---
title: "tagproc: getting your Wildlife Computers tag data from raw to ready"
author: "David Sweeney"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
R.utils::sourceDirectory('C:/Users/marec/Docs/tagproc/R')
```

In this tutorial, we will be using data from ZcTag059. To begin, I am going to clean up the data a little bit and create a new folder within our Wildlife Computers tag data folder that has data with standardized column names as used by the tools in this package. This step is not necessary to use other tools in the package, however, it might make things easier as no manual column header changes would need to be made.

```{r}
ZcTag059_folder <- "C:/Users/marec/Docs/ZcTag059-Portal-Folder"
prettifyWC(ZcTag059_folder)
```

The new folder that is created is located within the tag data folder and is named WC-pretty. Opening up this new folder, you will see the same data files, but they will have been cleaned and prettified. 

We are next going to pull in the animal track for this animal and perform some filtering. We will run the Douglas-argos filter and Freitas filter on the argos data and a basic GPS filter on our GPS data.

```{r}
#pull in data
GPS_data <- read.csv("C:/Users/marec/Docs/ZcTag059-Portal-Folder/WC-pretty/ZcTag058-164613-3-FastGPS.csv")
Argos_data <- read.csv("C:/Users/marec/Docs/ZcTag059-Portal-Folder/WC-pretty/164613-Locations.csv")

#run filters
DF_data <- douglas.filter(Argos_data, argos_method = 'K', method = 'DAR', 
                          keep_lc = 1, maxredun = 3, duplrec = 'offset', 
                          minrate = 15, ratecoef = 20, r_only = FALSE)$retained
FF_data <- freitas.filter(Argos_data, vmax = 2, ang = c(15, 25), distlim = c(2.5, 5))
GF_data <- gps.filter(GPS_data, min.sat = 5, max.residual = 35)$retained
```

I will now create an estimated track from a CRAWL model. The estimated track can have locations predicted for different time intervals. Here I will be using a 30 minute interval. See the crawl package for more options on possible time intervals.

```{r}
CRAWL_data <- crawl.apply(DF_data, model.interval = '30 mins', 
                          crs = 2230, land.adjust = NULL, img.path = NULL)
```

Now we can plot the CRAWL data to see how it looks. This plotting tool is the most basic location plotting tool in the package. Later on, we will use the `spatial.map` function to plot our data over ocean topography.

```{r, fig.height=4, fig.width=7, fig.align='center'}
tag.mapper(CRAWL_data$data, zoom = 1, lon.offset = 0, lat.offset = 0,
                       lwd = .5, pch = 1, cex = .5, col = "black", 
                       mars = c(1, 1, 1, 1), mapfile = NULL)
```

As mentioned above, we can also plot the animal track on a map after converting our data to a spatial object. Additionally, we can calculate a home range estimates and add them to the map. Before using the `spatial.map` function, however, you need to make sure you have internet connection as the topography data is pulled from the internet upon calling this funtion.

```{r, fig.height=4, fig.width=7, fig.align='center'}
#find home ranges (95% and 50%)
HR_data <- home.range(DF_data, perc = c(50, 95), kernel.method = 'href', unout = 'km2')

#plot all data
spatial.map(CRAWL_data$lines, CRAWL_data$points, HR_data[[1]], HR_data[[2]], 
            color = c('red','black', 'orange' ,'yellow'), 
            size = c(1.5, .25, 1, 1), title = 'KDE Home Ranges', subtitle = '95% and 50%')
```

We should also view the dive profile of this individual. However, before we do that we should split our dive behavior file into dive data and message data using the `split.dive.msg` function in this package.

```{r, fig.height=4, fig.width=7, fig.align='center'}
#pull in data
Beh_data <- read.csv("C:/Users/marec/Docs/ZcTag059-Portal-Folder/WC-pretty/164613-Behavior.csv")

#split behavior data
split_Beh <- split.dive.msg(Beh_data, kclusters = 2)

#plot dives
diveplot(split_Beh$Dives)
```

Now that we see what the dive profile looks like, we can also look at some simple summary stats found by the dive.summary tool. We will allow for kmeans analysis to separate deep/long from shallow/short dives.

```{r}
#collect summary data
dive.summary(split_Beh$Dives, forage.cutoff = 'kmeans')
```

Next, we can visualize the solar and lunar data associated with our tagged whale's diving behavior. Because `bhr.interpolate` only pulls prior locations and future locations, not the closest location in time regardless, the first few dives will not be shown as no location data is associated with them.

```{r, fig.height=4, fig.width=7, fig.align='center'}
#associate CRAWL locations with diving behavior
# and crop data to only dives that go below 800m depth
DIVE_data <- bhvr.interpolate(split_Beh$Dives, CRAWL_data$data)
DIVE_data <- DIVE_data[which(DIVE_data$DepthAvg > 800),]

#get solar and lunar data
SL_data <- sun.moon(DIVE_data)

#plot it 
plot.sunmoon(SL_data, xlab = 'Deep Dive Number')
```

We can also view bathymetry data in association with our tag data.

```{r, fig.height=4, fig.width=7, fig.align='center'}
#collect bathymetry data
BATHY_data <- bathy.sync(SL_data, z.radius = .25)

#plot data
plot.seafloor(BATHY_data, xlab = "Deep Dive Number")
```
